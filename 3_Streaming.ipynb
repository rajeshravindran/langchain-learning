{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c93a976-9ae8-4b51-8b5e-25715c181753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "import utility as ut\n",
    "\n",
    "OPENAI_API_KEY = ut.OPENAI_API_KEY\n",
    "LANGSMITH_API_KEY = ut.LANGSMITH_API_KEY\n",
    "MODEL_NAME = ut.MODEL_NAME\n",
    "print(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a380f6-e5ea-43ff-a8e3-9767447c0ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "agent = create_agent(\n",
    "    model = MODEL_NAME,\n",
    "    system_prompt = \"You are a full stack comedian\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbe5589-625d-421f-9a01-0cd31f8c2561",
   "metadata": {},
   "source": [
    "NO STREAMING INVOKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "672b3ff7-74f9-403b-81ce-03bc6fe01249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms? \n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\":\"Tell me a joke\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e1bc3-332b-4c71-bff4-cc535bc38fea",
   "metadata": {},
   "source": [
    "# VALUES\n",
    "this streaming mode is explained in previous examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f59fc01-53d2-4379-b41a-133328fa6835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Tell me sports joke\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Why do basketball players love donuts?\n",
      "\n",
      "Because they can't resist a good dunk! ðŸ©ðŸ€\n"
     ]
    }
   ],
   "source": [
    "#Stream = values\n",
    "for step in agent.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Tell me sports joke\"\n",
    "            }\n",
    "        ]\n",
    "    }, \n",
    "    stream_mode = \"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9292554b-3bce-4b0c-bfb5-487291dd0da0",
   "metadata": {},
   "source": [
    "# Messages\n",
    "Messages stream data token by token - the lowest latency possible. this is perfect for interactive applications like chatbots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93c01ba3-c5e2-4ef6-8ef7-3f5eb13f94d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a cozy little house, not too far away,  \n",
      "Lived a family of four, full of love every day.  \n",
      "With a mom who baked cookies, warm from the oven,  \n",
      "And a dad who told stories, the kind youâ€™re lovinâ€™.  \n",
      "\n",
      "Thereâ€™s a sister named Lily, with a spirit so bright,  \n",
      "She dances like daisies in the soft morning light.  \n",
      "And a brother named Ben, always ready to play,  \n",
      "With a smile that could chase all the gray clouds away.  \n",
      "\n",
      "They have a fluffy dog, named Max, oh so fun,  \n",
      "Who chases his tail in the warm summer sun.  \n",
      "Together they picnic, under trees, green and tall,  \n",
      "With sandwiches, laughter, and games for them all.  \n",
      "\n",
      "In the evening, they gather, with blankets in tow,  \n",
      "To watch stars in the sky, while the cool breezes blow.  \n",
      "With stories and laughter, they share all their dreams,  \n",
      "In this family of love, everythingâ€™s better, it seems.  \n",
      "\n",
      "So hereâ€™s to the moments, both big and the small,  \n",
      "In a family like this, thereâ€™s room for us all.  \n",
      "With joy in our hearts, and kindness in hand,  \n",
      "Together weâ€™ll flourish, together weâ€™ll stand!"
     ]
    }
   ],
   "source": [
    "for token, metadata in agent.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Write me a Family friendly poem\"\n",
    "            }\n",
    "        ]\n",
    "    }, \n",
    "    stream_mode = \"messages\"\n",
    "):\n",
    "    print(f\"{token.content}\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24bfef7-c9f4-48d8-b018-6e26b4393ad2",
   "metadata": {},
   "source": [
    "# TOOLS CAN STREAM TOO!\n",
    "Streaming generally means delivering information to user before the final result is ready. there are many cases where this is useful\n",
    "\n",
    "a `get_stream_writer` writer allows to easily stream `custom` data from sources you create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3003b4-7c3b-4f48-b1a0-93f2640867fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('values', {'messages': [HumanMessage(content='What is the weather in London?', additional_kwargs={}, response_metadata={}, id='8ddff6ca-603e-428a-8c2c-b170ad6769cb')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in London?', additional_kwargs={}, response_metadata={}, id='8ddff6ca-603e-428a-8c2c-b170ad6769cb'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 51, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cd9WOfjDmkiNVzg2qGJSfLCYBpg9o', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--8daa7a71-f163-43a7-a76f-43b396db4a1a-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'London'}, 'id': 'call_fbSpfQIqsmeHzVKSUKhEKIHs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 51, 'output_tokens': 14, 'total_tokens': 65, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]})\n",
      "('custom', 'Looking up data for city: London')\n",
      "('custom', 'Acquired data for city:London')\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in London?', additional_kwargs={}, response_metadata={}, id='8ddff6ca-603e-428a-8c2c-b170ad6769cb'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 51, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cd9WOfjDmkiNVzg2qGJSfLCYBpg9o', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--8daa7a71-f163-43a7-a76f-43b396db4a1a-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'London'}, 'id': 'call_fbSpfQIqsmeHzVKSUKhEKIHs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 51, 'output_tokens': 14, 'total_tokens': 65, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"It's always sunny in London!\", name='get_weather', id='23261646-f714-4d3d-bdbe-d13fc30d3dc1', tool_call_id='call_fbSpfQIqsmeHzVKSUKhEKIHs')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in London?', additional_kwargs={}, response_metadata={}, id='8ddff6ca-603e-428a-8c2c-b170ad6769cb'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 51, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cd9WOfjDmkiNVzg2qGJSfLCYBpg9o', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--8daa7a71-f163-43a7-a76f-43b396db4a1a-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'London'}, 'id': 'call_fbSpfQIqsmeHzVKSUKhEKIHs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 51, 'output_tokens': 14, 'total_tokens': 65, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"It's always sunny in London!\", name='get_weather', id='23261646-f714-4d3d-bdbe-d13fc30d3dc1', tool_call_id='call_fbSpfQIqsmeHzVKSUKhEKIHs'), AIMessage(content='The weather in London is sunny!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 79, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cd9WPL93PTMgN9UEsYE3cjWxUpIHb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--64fd3089-8980-4169-8022-80f4fbeb504c-0', usage_metadata={'input_tokens': 79, 'output_tokens': 8, 'total_tokens': 87, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]})\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_stream_writer\n",
    "\n",
    "def get_weather(city:str) -> str:\n",
    "    \"\"\"Get weather for a given city\"\"\"\n",
    "    writer = get_stream_writer()\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city:{city}\")\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=MODEL_NAME,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the weather in London?\"\n",
    "            }\n",
    "        ]\n",
    "    }, \n",
    "    stream_mode = [\"values\", \"custom\"],\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677c93d1-a564-467a-8a33-f287e1509076",
   "metadata": {},
   "source": [
    "# Try different modes \n",
    "modify the stream mode and the select to produce different results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52778997-0cc0-441a-a2cb-c9ac049c7bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up data for city: London\n",
      "Acquired data for city:London\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the weather in London?\"\n",
    "            }\n",
    "        ]\n",
    "    }, \n",
    "    stream_mode = [\"values\", \"custom\"],\n",
    "):\n",
    "    if chunk[0] == \"custom\":\n",
    "        print(chunk[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6f0409-c9ef-4521-8a5b-395ec4667722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
